\chapter{绪论}
本章首先阐述了本课题的研究背景及现实意义，然后介绍国内外针对该问题的研究与进展。同时说明在实际应用中存在的问题和可进一步优化的方法。最后介绍本论文的整体组织结构。
\section{研究背景与意义}
近年来，以神经网络[引用]为代表的深度学习方法在图像处理、机器视觉、自然语言处理等诸多应用领域取得了巨大突破。自2012年AlexNet[引用]以绝对优势夺得ImageNet冠军后，神经网络逐渐得到学术界、工业界的广泛关注，开启了人工智能新篇章。随后各种性能更优、结构更复杂的网络如雨后春笋般层出不穷。如VGG、inception系列、resnet系列，denseNet等[引用]。同时，鉴于卷积神经网络在图像分类领域的优异表现，业界将其应用到目标检测、图像分割等领域。如fast rcnn系列、yolo系列、FPN、R-FCN等[引用]。在自然语言处理领域，涌现出了一系列以循环神经网络[引用]为基础的深度学习方法，在机器翻译、文本分析、阅读理解等[引用]问题上取得了显著进步，达到甚至超越人类水平。\\
因为神经网络参数量、计算量巨大，往往需要花费数天，乃至更长的时间。如最初的AlexNet[引用]，需要5-6天训完。使得网络更新迭代设计周期变长，极大限制了科研人员的研究进度。随着网络结构复杂化迭代周期过长的问题尤为严重。分布式训练神经网络则能极大缩短训练周期，加速研究迭代、产品孵化等。同时，随着神经网络的不断发展以及社会对人工智能应用需求的提升，深度学习所需的数据量、网络模型也越来越大，单台计算机算力已经很难甚至无法满足其计算要求。为了减少神经网络的训练时间和适应不断增长的算力要求，分布式训练神经网络是必然选择。\\
本课题围绕着分布式训练神经网络的效率和精度进行展开，旨在保证网络性能前提下，提高分布式训练神经网络效率，提高训练加速比，缩短训练时间。本课题不仅能解决现今训练神经网络时间过长的问题， 更为今后单机场景下无法完成训练的神经网络提供了高效的训练方法。这对于现阶段和可预见未来都有重要实用价值，促进神经网络的发展，对人工智能的发展有深远意义。

\section{研究现状}
随着人工智能的快速发展，为提升训练效率，满足生产需求。业界已针对分布式深度学习系统进行了深入的研究。目前业界主流深度学习框架同时支持parameter servers和horovod进行分布式训练。如tensorflow，pytorch，mxnet等[引用]均支持pamameter servers和horovod。在通信效率上，针对神经网络的训练特点，CMU邢波教授课题组提出了一系列经典有效的方法：WFBP，SFB等。其petuum系统也受到广泛关注。在训练精度上，业界针对大batch size训练提出了一系列更新算法，保证大batch size的训练精度。如facebook何恺明等[引用]就提出线性增大学习率的方法保证了在batch size达到8k时，和单机batch size等于256时一致的精度，使得大规模分布式训练神经网络成为可能。随后，伯克利尤洋等提出LARS算法[引用],在保证精度的情况下，进一步将batch size扩大到32k；紧接着Google Brain提出动态调整batch size的方法[引用]将batch size提升到64k。
\subsection{分布式框架：ps，horovod介绍}
目前主流深度学习框架均支持parameter servers和horovod。parameter servers最早由smola教授提出，最终由学生李沐实现[引用]。其提供同步、异步、半异步的更新方式。因其灵活的更新方式和良好的性能得到业界广泛认可。参数服务器通过key-value键值对来管理参数。通常情况下，参数服务器是以去中心化的形式分散在多个节点，各个节点负责部分数据。其通信架构如图1.1所示。所有的server共同维护整个网络的参数，server之间可 以相互通信，client端将模型参数根据key分别传给相应管理这部分参数的server。Client之间不存在通信。\\
\begin{figure}[htp]
\centering
\includegraphics[width=10cm]{ps_comm_pattern}
\caption{参数服务器通信架构图}
\end{figure}
参数服务器主要有5大优点:(1)通信高效，在异步情况下不会拖慢计算;(2)支持弹性一致性，其可通过放宽模型一致性条件，达到算法收敛速度和系统性能之间的平衡。(3) 扩展性强，增加节点时无需重启网络;(4)机器错误恢复时间短，Vector Clock容许网络错 误了;(5)易用性，其全局共享的参数使用向量和矩阵表示，而这些又可以用高性能多线程库进行优化。\\
参数服务器下，训练流程如图1.2所示。训练主要包含4部分:(1)worker节点各自计算梯度;(2)worker节点将各自梯度push到server端;(3)server端对所有梯度进行求和平均并更新模型参数w;(4)worker节点从server端pull最新的参数w。\\
\begin{figure}[htp]
\centering
\includegraphics[width=10cm]{ps_update_way}
\caption{参数服务器下训练流程图}
\end{figure}
horovod[引用]是uber基于百度ring-allredue[引用]的通信方式（考虑加ring-allreduce的图？），提出了的分布式通信框架，因为其优异的性能和简单的使用方式，在业界引起广泛关注。horovod基于mpi实现，为提高分布式通信的效率，提出tensor fusion和分层级同步策略等方法，极大提高了分布式训练效率。

\subsection{目前业界最新训练硬件：fp16，bf16训练}
因为传统硬件计算基本以浮点数位主，目前绝大多数训练场景中都采用浮点数运算。而神经网络本身就存在随机性和容错性的特点，其计算精度并不需要达到浮点数的精度，为了节省内存，带宽，以及支持低精度计算的硬件设备上提升计算效率，业界提出了两种主流的低精度格式的数据表示用于训练神经网络。分别是IEEE半精度fp16和bfloat16格式。经过工业界验证，用这两种数据格式训练神经网络均保证训练精度，逐渐成为主流。\\
2017年Micikevicius P等为节省训练的内存开销，提出混合精度训练[Micikevicius P , Narang S , Alben J , et al. Mixed Precision Training[J]. 2017.]的方法，使用IEEE半精度格式存储所有网络层的中间结果。相对于原始32位浮点数计算而言，训练网络模型所消耗的内存减小了一半；同时，为了弥补半精度表示所带来的损失，文章提出混合精度更新方法，如图1.3所示。在设计损失函数时，适当放大损失函数权重的方法来保证训练精度。\\
\begin{figure}[htp]
\centering
\includegraphics[width=10cm]{fp16_training_steps}
\caption{混合精度训练迭代方法}
\end{figure}
文章也指出，当前大部分硬件不支持半精度计算，所以此方法在现有硬件基础上只能节省内存，由于实际计算都是先把半精度数值转换成浮点数再计算，存在一定的额外开销，使得计算速度相对有所下降。目前Nvidia的最新硬件，如Volta系列，turing系列已经支持半精度计算，可进一步提升计算效率。\\
目前，支持bfloat16计算的硬件只有google的TPU。受硬件限制，深度学习框架中只有tensorflow对bfloat16提供了数据支持，其他框架如pytorch，mxnet等则暂时不支持。

\section{本文工作}
本课题根据现有硬件特点，提出两种分布式数据同步方式，在保证训练精度的情况下，通过减小网络通信量，以减小通信开销，提高训练效率。第一种是半精度同步方式；第二种是bfloat16同步方式。因为目前以mpi为基础的horovod通信框架效率高于parameter servers，所以本文基于horovod实现这两种同步方式。下面对其主要实现过程以及需要利用的相关知识进行介绍。
\subsection{半精度同步方式}
根据现有硬件特点可知，现阶段绝大部分硬件只支持浮点运算，即使目前主流深度学习框架支持半精度训练，其做法只是将半精度输入转换成浮点数再进行计算，使得计算效率低于正常浮点计算。而根据神经网络的特点，半精度数据即可满足其训练需求。\\
分布式训练相对于单机训练方式而言，仅多了同步梯度的过程，其同步开销大小决定了分布式训练效率的高低。考虑到现有硬件的特点和深度学习对半精度数据的友好性，本文提出使用浮点数据计算，半精度梯度数据同步的训练方法。通过减少网络通信量的方法，提高分布式训练效率。本文提出的半精度同步方式，主要包含下面三步:\\
1. 在进行梯度同步之前，将各层梯度转换成半精度表示，对于超过半精度表示范围的梯度，通过阈值截取的方式将其转换成固定的大小，避免无效数据的产生；
2. 基于horovod实现自定义的半精度加法，\{为弥补数据转换导致的信息损失，将梯度转换为浮点数进行求和并适当增大梯度权重，\}将其传入mpi用于梯度求和；
3. 在完成半精度同步后，将半精度的梯度转换为浮点数表示，用于下一次迭代计算。

\subsection{bfloat16同步方式}
bfloat16数据格式所需的数据位与半精度数据格式一致。其传输的数据量不变，而其指数位与浮点数一致，精度位比浮点数少了16位。相对于半精度数据而言有两个优势：1.在与浮点数进行转换的过程中，直接将浮点数的低16位舍去即可，无需对数据位进行转化。其与浮点数的转化更为高效；2.因为其指数位长度与浮点数一致，故其表示范围与浮点数基本一致，在进行数据转化时，不存在数值越界的情况。同时，因为bfloat16指数位相对较长，使得其精度位相对较短，其表示的精度相对半精度数据要差。\\
bfloat16同步方式的实现方法与半精度数据同步方式相似，包含下面三个步骤：
1. 在进行梯度同步之前，将各层梯度转换成bfloat16数据格式；
2. 基于horovod实现自定义的bfloat16的加法，\{为弥补数据转换导致的信息损失，将梯度转换为浮点数进行求和并适当增大梯度权重，\}将其传入mpi用于bfloat16梯度的求和；
3. 在完成bfloat16数据同步后，将blfloat16的梯度转换为浮点数表示，用于下一次迭代计算。
\section{本文组织结构}
本文针对现有硬件特点和神经网络对低精度数据的友好性，提出两种低精度数据传输方式，在保证训练精度的前提下，减小数据通信量，提升了分布式训练效率。文章主要探讨了在分布式训练神经网络中低精度数据传输的可行性以及不同数据表示的优劣点。本文主要分为五章，详细安排如下：\\
第一章，绪论。主要对本课题的研究背景和研究意义进行介绍，系统介绍了目前以神经网络为主的深度学习的发展，分布式深度学习系统的发展和低精度训练神经网络的最新进展以及现阶段计算硬件的限制。并说明了本文的主要研究内容以及对应的创新点。最后说明了本文的组织结构。\\
第二章，分布式训练神经网络和低精度训练的相关研究。








